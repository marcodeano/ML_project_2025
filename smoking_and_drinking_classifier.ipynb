{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idee\n",
    "\n",
    "**Questa sezione viene utilizzata per scrivere tutto ciò che ci viene in mente da poter implementare per rendere il progetto più interessante**\n",
    "\n",
    "- Usare le colonne di ground truth (drink e smoke) come features vere e proprie per la classificazione di smoke e drink\n",
    "- Provare a fare classificazione senza includere le colonne di ground truth (drink e smoke) come features\n",
    "- Fare un modello che predica se il paziente mente oppure no (probabilmente si fare clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sooyoungher/smoking-drinking-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file_name = \"smoking_driking_dataset_Ver01.csv\"\n",
    "file_path = f\"{path}/{file_name}\"\n",
    "dataset = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi iniziale del dataset\n",
    "print(\"\\nPrime righe del dataset:\")\n",
    "print(dataset.head())\n",
    "\n",
    "print(\"\\nDimensioni del dataset:\")\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"\\nTipi di dati:\")\n",
    "print(dataset.info())\n",
    "\n",
    "print(\"\\nStatistiche descrittive di base:\")\n",
    "print(dataset.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prime considerazioni\n",
    "\n",
    "I dati sembrano non contenere dati nulli o NaN, però si osserva facilmente che per alcune feature ci sono dei dati che sembrano essere irrealistici (Es.: per la feature **waistline** la media risulta essere _81_, il 4° quartile _87_ e il valore massimo _999_); quindi nonostante la non presenza di valori nulli, bisogna verificare se sono presenti valori mancanti codificati in altro modo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke = dataset[\"SMK_stat_type_cd\"].value_counts()\n",
    "drink = dataset[\"DRK_YN\"].value_counts()\n",
    "\n",
    "# Distribuzione SMK_stat_type_cd\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1) # Num righe, num colonne, posizione \n",
    "sns.barplot(x=smoke.index, y=smoke.values, palette=\"Blues_d\")\n",
    "plt.title(\"Distribuzione delle classi relative al fumo\")\n",
    "plt.xlabel(\"Tipo di fumatore\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "\n",
    "# Distribuzione DRK_YN\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=drink.index, y=drink.values, palette=\"Greens_d\")\n",
    "plt.title(\"Distribuzione delle classi relative al bere\")\n",
    "plt.xlabel(\"Bevitore (Y/N)\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mod = dataset.drop(columns=[\"sex\", \"SMK_stat_type_cd\", \"DRK_YN\"])\n",
    "\n",
    "# Boxplot per le principali feature numeriche\n",
    "plt.figure(figsize=(25, 20))\n",
    "for i, col in enumerate(dataset_mod.columns):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    sns.boxplot(y=dataset_mod[col], color=\"skyblue\")\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dei valori massimi e distanza dal secondo massimo e dalla media\n",
    "\n",
    "for col in dataset_mod.columns:\n",
    "    max = dataset_mod[col].max()\n",
    "    max_count = (dataset_mod[col] == max).sum()\n",
    "    second_max = dataset_mod[col][dataset_mod[col] < max].max()\n",
    "    distance_max = max - second_max\n",
    "    mean_value = dataset[col].mean()\n",
    "    distance_mean = max - mean_value\n",
    "\n",
    "    print(f\"Colonna: {col}\")\n",
    "    print(f\"    -Valore massimo: {max}\")\n",
    "    print(f\"    -Occorrenze del massimo: {max_count}\")\n",
    "    print(f\"    -Secondo massimo: {second_max}\")\n",
    "    print(f\"    -Distanza tra massimo e secondo massimo: {distance_max}\")\n",
    "    print(f\"    -Media: {mean_value}\")\n",
    "    print(f\"    -Distanza tra massimo e media: {distance_mean}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinazione del numero di valori \"fuori scala\" (outliers) per ogni feature\n",
    "\n",
    "for col in dataset_mod.columns:\n",
    "    Q1 = dataset_mod[col].quantile(0.25)\n",
    "    Q3 = dataset_mod[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = dataset_mod[(dataset_mod[col] < lower_bound) | (dataset_mod[col] > upper_bound)]\n",
    "    print(f\"Colonna: {col}\")\n",
    "    print(f\"    -Valori fuori scala: {len(outliers)}\")\n",
    "    print(f\"    -Limiti: {lower_bound} - {upper_bound}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerazioni\n",
    "\n",
    "Un'analisi più approfondita ha permesso di individuare la presenza di alcuni outlier in specifiche feature, in particolare confrontando il valore massimo presente nel dataset con il secondo valore massimo per ciascuna di esse; è importante sottolineare però che non tutte le feature mostrano grosse differenze tra il primo e il secondo massimo ed in molti casi sono presenti molti valori tra il massimo e la media.\n",
    "\n",
    "Sono state fatte dunque delle brevi ricerche per capire quali valori fossero plausibili per ogni feature e quali no, è stato deciso di stabilire una soglia massima accettabile per alcune di queste; queste soglie sono state definite con l'obiettivo di preservare il maggior numero possibile di righe del dataset originario ma eliminando allo stesso tempo i casi clinicamente estremi e rari, in modo da ottenere un dataset più generico, privo di situazioni patologiche estreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    \"waistline\": 200,\n",
    "    \"sight_left\": 4,\n",
    "    \"sight_right\": 4,\n",
    "    \"SBP\": 240,\n",
    "    \"DBP\": 160,\n",
    "    \"BLDS\": 600,\n",
    "    \"tot_chole\": 1000,\n",
    "    \"HDL_chole\": 700,\n",
    "    \"LDL_chole\": 2000,\n",
    "    \"triglyceride\": 3500,\n",
    "    \"serum_creatinine\": 30,\n",
    "    \"SGOT_AST\": 2000,\n",
    "    \"SGOT_ALT\": 2000,\n",
    "    \"gamma_GTP\": 900,\n",
    "}\n",
    "\n",
    "for col, threshold in thresholds.items():\n",
    "    dataset.loc[dataset[col] > threshold, col] = None\n",
    "\n",
    "# Rimozione delle righe con valori mancanti\n",
    "dataset_cleaned = dataset.dropna(subset=thresholds.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora verranno rieseguite tutte le operazioni di visualizzazione dei dati presenti nel dataset per comprendere la distribuzione di questi dopo l'operazione di rimozione degli outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi iniziale del dataset\n",
    "print(\"\\nPrime righe del dataset:\")\n",
    "print(dataset_cleaned.head())\n",
    "\n",
    "print(\"\\nDimensioni del dataset:\")\n",
    "print(dataset_cleaned.shape)\n",
    "\n",
    "print(\"\\nTipi di dati:\")\n",
    "print(dataset_cleaned.info())\n",
    "\n",
    "print(\"\\nStatistiche descrittive di base:\")\n",
    "print(dataset_cleaned.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke = dataset_cleaned[\"SMK_stat_type_cd\"].value_counts()\n",
    "drink = dataset_cleaned[\"DRK_YN\"].value_counts()\n",
    "\n",
    "# Distribuzione SMK_stat_type_cd\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1) # Num righe, num colonne, posizione \n",
    "sns.barplot(x=smoke.index, y=smoke.values, palette=\"Blues_d\")\n",
    "plt.title(\"Distribuzione delle classi relative al fumo\")\n",
    "plt.xlabel(\"Tipo di fumatore\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "\n",
    "# Distribuzione DRK_YN\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=drink.index, y=drink.values, palette=\"Greens_d\")\n",
    "plt.title(\"Distribuzione delle classi relative al bere\")\n",
    "plt.xlabel(\"Bevitore (Y/N)\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mod = dataset_cleaned.drop(columns=[\"sex\", \"SMK_stat_type_cd\", \"DRK_YN\"])\n",
    "\n",
    "# Boxplot per le principali feature numeriche\n",
    "plt.figure(figsize=(25, 20))\n",
    "for i, col in enumerate(dataset_mod.columns):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    sns.boxplot(y=dataset_mod[col], color=\"skyblue\")\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dei valori massimi e distanza dal secondo massimo e dalla media\n",
    "\n",
    "for col in dataset_mod.columns:\n",
    "    max = dataset_mod[col].max()\n",
    "    max_count = (dataset_mod[col] == max).sum()\n",
    "    second_max = dataset_mod[col][dataset_mod[col] < max].max()\n",
    "    distance_max = max - second_max\n",
    "    mean_value = dataset[col].mean()\n",
    "    distance_mean = max - mean_value\n",
    "\n",
    "    print(f\"Colonna: {col}\")\n",
    "    print(f\"    -Valore massimo: {max}\")\n",
    "    print(f\"    -Occorrenze del massimo: {max_count}\")\n",
    "    print(f\"    -Secondo massimo: {second_max}\")\n",
    "    print(f\"    -Distanza tra massimo e secondo massimo: {distance_max}\")\n",
    "    print(f\"    -Media: {mean_value}\")\n",
    "    print(f\"    -Distanza tra massimo e media: {distance_mean}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinazione del numero di valori \"fuori scala\" (outliers) per ogni feature\n",
    "\n",
    "for col in dataset_mod.columns:\n",
    "    Q1 = dataset_mod[col].quantile(0.25)\n",
    "    Q3 = dataset_mod[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = dataset_mod[(dataset_mod[col] < lower_bound) | (dataset_mod[col] > upper_bound)]\n",
    "    print(f\"Colonna: {col}\")\n",
    "    print(f\"    -Valori fuori scala: {len(outliers)}\")\n",
    "    print(f\"    -Limiti: {lower_bound} - {upper_bound}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta terminata la fase di analisi e pulizia dei dati, sarebbe opportuno procedere con le operazioni di encoding e scaling dei dati (visto che sono presenti features con valori molto grandi e altre con valori più piccoli), però pensiamo sia più opportuno fare queste operazioni eventualmente in un secondo momento a seconda dei modelli di ML che decidiamo di utilizzare.\n",
    "Per ora ci limitiamo a fare l'encoding delle feature categoriali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9k/0zc4z1md49d58jhbq4fgqjg40000gn/T/ipykernel_1259/3293868468.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_cleaned[col] = encoder.fit_transform(dataset_cleaned[col])\n",
      "/var/folders/9k/0zc4z1md49d58jhbq4fgqjg40000gn/T/ipykernel_1259/3293868468.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_cleaned[col] = encoder.fit_transform(dataset_cleaned[col])\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"sex\", \"DRK_YN\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    encoder = LabelEncoder()\n",
    "    dataset_cleaned[col] = encoder.fit_transform(dataset_cleaned[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito riportiamo un semplice modello di albero decisionale per vedere che lower bound di accuratezza abbiamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisione del dataset in feature e target (X e Y)\n",
    "target_smoke = \"SMK_stat_type_cd\"\n",
    "target_drink = \"DRK_YN\"\n",
    "X_smoke = dataset_cleaned.iloc[:, dataset_cleaned.columns != target_smoke]\n",
    "#X_smoke = dataset_cleaned.drop(columns=[\"SMK_stat_type_cd\", \"DRK_YN\"])\n",
    "Y_smoke = dataset_cleaned[target_smoke]\n",
    "X_drink = dataset_cleaned.iloc[:, dataset_cleaned.columns != target_drink]\n",
    "#X_drink = dataset_cleaned.drop(columns=[\"SMK_stat_type_cd\", \"DRK_YN\"])\n",
    "Y_drink = dataset_cleaned[target_drink]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.6240\n"
     ]
    }
   ],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_smoke, Y_smoke, test_size=0.3, random_state=42)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train_s, y_train_s)\n",
    "y_pred = model.predict(X_test_s)\n",
    "accuracy = accuracy_score(y_test_s, y_pred)\n",
    "print(f\"Accuratezza: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza: 0.6434\n"
     ]
    }
   ],
   "source": [
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_drink, Y_drink, test_size=0.3, random_state=42)\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train_d, y_train_d)\n",
    "y_pred = model.predict(X_test_d)\n",
    "accuracy = accuracy_score(y_test_d, y_pred)\n",
    "print(f\"Accuratezza: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
