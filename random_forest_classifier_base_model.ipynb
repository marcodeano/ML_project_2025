{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcodeano/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/marcodeano/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from load_data_and_distribution_analisys import split_dataset_v1, load_dataset_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esempio con Random Forest\n",
    "\n",
    "Iniziamo ad utilizzare dei modelli un po' pi√π complessi e poco alla volta andiamo a migliorare il nostro modello con tecniche di preprocessing e tuning dei parametri; partiamo da una RandomForest (da adesso in poi le predizioni e le metriche, verranno salvate in nomi di variabili che contengono il nome del modello e la lettera 's' per smoke e 'd' per drink).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.8).\n",
      "Path to dataset files: /Users/marcodeano/.cache/kagglehub/datasets/sooyoungher/smoking-drinking-dataset/versions/2\n",
      "   sex  age  height  weight  waistline  sight_left  sight_right  hear_left  \\\n",
      "0    1   35     170      75       90.0         1.0          1.0        1.0   \n",
      "1    1   30     180      80       89.0         0.9          1.2        1.0   \n",
      "2    1   40     165      75       91.0         1.2          1.5        1.0   \n",
      "3    1   50     175      80       91.0         1.5          1.2        1.0   \n",
      "4    1   50     165      60       80.0         1.0          1.2        1.0   \n",
      "\n",
      "   hear_right    SBP  ...  LDL_chole  triglyceride  hemoglobin  urine_protein  \\\n",
      "0         1.0  120.0  ...      126.0          92.0        17.1            1.0   \n",
      "1         1.0  130.0  ...      148.0         121.0        15.8            1.0   \n",
      "2         1.0  120.0  ...       74.0         104.0        15.8            1.0   \n",
      "3         1.0  145.0  ...      104.0         106.0        17.6            1.0   \n",
      "4         1.0  138.0  ...      117.0         104.0        13.8            1.0   \n",
      "\n",
      "   serum_creatinine  SGOT_AST  SGOT_ALT  gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
      "0               1.0      21.0      35.0       40.0               1.0       1  \n",
      "1               0.9      20.0      36.0       27.0               3.0       0  \n",
      "2               0.9      47.0      32.0       68.0               1.0       0  \n",
      "3               1.1      29.0      34.0       18.0               1.0       0  \n",
      "4               0.8      19.0      12.0       25.0               1.0       0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_cleaned = load_dataset_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smoke, Y_smoke, X_drink, Y_drink = split_dataset_v1(dataset_cleaned)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_smoke, Y_smoke, test_size=0.3, random_state=42, stratify=Y_smoke)\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_drink, Y_drink, test_size=0.3, random_state=42, stratify=Y_drink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio smoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.82      0.84      0.83    167528\n",
      "         2.0       0.44      0.35      0.39     47377\n",
      "         3.0       0.51      0.56      0.54     58574\n",
      "\n",
      "    accuracy                           0.69    273479\n",
      "   macro avg       0.59      0.58      0.58    273479\n",
      "weighted avg       0.69      0.69      0.69    273479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "forest.fit(X_train_s, y_train_s)\n",
    "y_pred_rf_s = forest.predict(X_test_s)\n",
    "report = classification_report(y_test_s, y_pred_rf_s)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72    135539\n",
      "           1       0.72      0.73      0.73    137940\n",
      "\n",
      "    accuracy                           0.72    273479\n",
      "   macro avg       0.72      0.72      0.72    273479\n",
      "weighted avg       0.72      0.72      0.72    273479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "forest.fit(X_train_d, y_train_d)\n",
    "y_pred_rf_d = forest.predict(X_test_d)\n",
    "report = classification_report(y_test_d, y_pred_rf_d)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procediamo con il selezionare un paio di parametri e combinarli tra loro per vedere quale modello ottiene i risultati migliori\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [5, 10, 20],\n",
    "    \"min_samples_split\": [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimators in parameters[\"n_estimators\"]:\n",
    "    for max_depth in parameters[\"max_depth\"]:\n",
    "        for min_samples_split in parameters[\"min_samples_split\"]:\n",
    "            forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42, class_weight=\"balanced\")\n",
    "            forest.fit(X_train_s, y_train_s)\n",
    "            y_pred_rf_s = forest.predict(X_test_s)\n",
    "            accuracy_rf_s = accuracy_score(y_test_s, y_pred_rf_s)\n",
    "            precision_rf_s = precision_score(y_test_s, y_pred_rf_s, average=\"weighted\")\n",
    "            recall_rf_s = recall_score(y_test_s, y_pred_rf_s, average=\"weighted\")\n",
    "            f1_rf_s = f1_score(y_test_s, y_pred_rf_s, average=\"weighted\")\n",
    "            print(f\"n_estimators: {n_estimators}, max_depth: {max_depth}, min_samples_split: {min_samples_split}\")\n",
    "            print(f\"    Accuratezza: {accuracy_rf_s*100:.2f}%\")\n",
    "            print(f\"    Precisione: {precision_rf_s*100:.2f}%\")\n",
    "            print(f\"    Recall: {recall_rf_s*100:.2f}%\")\n",
    "            print(f\"    F1: {f1_rf_s*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La miglior scelta dei parametri risulta essere la seguente:\n",
    "- **n_estimators**: 100\n",
    "- **max_depth**: 20\n",
    "- **min_samples_split**: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.94      0.73      0.82    179620\n",
      "         2.0       0.42      0.58      0.49     52107\n",
      "         3.0       0.49      0.64      0.55     63795\n",
      "\n",
      "    accuracy                           0.68    295522\n",
      "   macro avg       0.62      0.65      0.62    295522\n",
      "weighted avg       0.75      0.68      0.70    295522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=50, random_state=42, class_weight=\"balanced\")\n",
    "forest.fit(X_train_s, y_train_s)\n",
    "y_pred_rf_s = forest.predict(X_test_s)\n",
    "report = classification_report(y_test_s, y_pred_rf_s)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_estimators in parameters[\"n_estimators\"]:\n",
    "    for max_depth in parameters[\"max_depth\"]:\n",
    "        for min_samples_split in parameters[\"min_samples_split\"]:\n",
    "            forest = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "            forest.fit(X_train_d, y_train_d)\n",
    "            y_pred_rf_d = forest.predict(X_test_d)\n",
    "            accuracy_rf_d = accuracy_score(y_test_d, y_pred_rf_d)\n",
    "            precision_rf_d = precision_score(y_test_d, y_pred_rf_d)\n",
    "            recall_rf_d = recall_score(y_test_d, y_pred_rf_d)\n",
    "            f1_rf_d = f1_score(y_test_d, y_pred_rf_d)\n",
    "            print(f\"n_estimators: {n_estimators}, max_depth: {max_depth}, min_samples_split: {min_samples_split}\")\n",
    "            print(f\"    Accuratezza: {accuracy_rf_d*100:.2f}%\")\n",
    "            print(f\"    Precisione: {precision_rf_d*100:.2f}%\")\n",
    "            print(f\"    Recall: {recall_rf_d*100:.2f}%\")\n",
    "            print(f\"    F1: {f1_rf_d*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La miglior scelta dei parametri risulta essere la seguente:\n",
    "- **n_estimators**: 100\n",
    "- **max_depth**: 20\n",
    "- **min_samples_split**: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73    147594\n",
      "           1       0.72      0.75      0.74    147928\n",
      "\n",
      "    accuracy                           0.73    295522\n",
      "   macro avg       0.73      0.73      0.73    295522\n",
      "weighted avg       0.73      0.73      0.73    295522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=50, random_state=42)\n",
    "forest.fit(X_train_d, y_train_d)\n",
    "y_pred_rf_d = forest.predict(X_test_d)\n",
    "report = classification_report(y_test_d, y_pred_rf_d)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che sono stati definiti i parametri migliori per le random forest, procediamo con la tecnica della feature selection con la speranza di migliorare i risultati di accuratezza, precisione, recall e f1_score; pensiamo sia un'operazione da compiere per poter ottenere risultati migliori, perch√® abbiamo a che fare con un dataset con 22 feature e il rischio di overfit c'√®. Probabilmente con una random forest questo rischio √® minore, per√≤ testiamo se anche con una random forest i risultati migliorano."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
